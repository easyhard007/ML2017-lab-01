{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.       -0.749474 -0.833214 ...,  0.       -0.82     -1.      ]\n",
      " [-1.        0.318196 -0.857143 ...,  0.       -1.       -0.9998  ]\n",
      " [ 1.       -0.611429 -0.696429 ...,  0.       -0.88     -1.      ]\n",
      " ..., \n",
      " [ 1.       -0.924812 -0.940357 ..., -1.       -0.8      -1.      ]\n",
      " [ 1.       -0.799398 -0.868929 ...,  0.       -0.9      -0.997   ]\n",
      " [ 1.       -0.781955 -0.657857 ...,  0.       -0.92     -0.994   ]]\n",
      "[-1. -1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1.\n",
      " -1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.\n",
      "  1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.\n",
      " -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1.\n",
      " -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.\n",
      " -1.  1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1.\n",
      "  1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      " -1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      "  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
      "  1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1.  1.\n",
      " -1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1. -1.\n",
      " -1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.\n",
      " -1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
      "  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1.\n",
      "  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.\n",
      "  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.\n",
      " -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.\n",
      " -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.\n",
      " -1.  1.  1.]\n",
      "[0.012999842900246071, 0.020289446926176301, -0.056396299378766494, 0.17799839330741063, 0.22161276405891464, 0.082749206154316801, 0.080489095052130852, 1.0889890119529166, 0.084998754506734317, 0.10150693843627914, -0.021000195700951962, 0.22099853070555775, -0.34918122731570134, 0.18266679271842667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = 0.001\n",
    "lr = 0.001\n",
    "iter = 100\n",
    "accuracy = 0.001\n",
    "lam = 0.0001 \n",
    "cost =0 \n",
    "\n",
    "\n",
    "\n",
    "m = 690\n",
    "m_train = 345\n",
    "m_test = 345\n",
    "features=14\n",
    "\n",
    "w=[0,0,0,0,0, 0,0,0,0,0, 0,0,0,0]\n",
    "grad = [0,0,0,0,0, 0,0,0,0,0, 0,0,0,0]\n",
    "yp = [0]*m\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    data = load_svmlight_file(\"C:\\\\Users\\\\easyh\\\\Desktop\\\\australian_scale\",n_features=features)\n",
    "    return data[0], data[1]\n",
    "\n",
    "X, y = get_data()\n",
    "X = X.toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=43)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "def costAndGrad(m,X,y):\n",
    "    global cost\n",
    "    cost = 0\n",
    "    for i in range (0,m):\n",
    "        yp[i] = 0\n",
    "        for j in range(0,features):\n",
    "            yp[i] = yp[i] + X[i][j] * w[j]\n",
    "\n",
    "        if(y[i]*yp[i]-1<0):\n",
    "            cost += (1-y[i]*yp[i])\n",
    "        #print (\"cost\",cost)\n",
    "            \n",
    "    for  j in range (0,features):\n",
    "        cost = cost + 0.5 * lam * w[j] * w[j]\n",
    "    \n",
    "    for j in range(0,features):\n",
    "        grad[j] = abs(lam*w[j])\n",
    "        for i in range(0,m):\n",
    "            if(y[i]*yp[i]-1<0):\n",
    "                grad[j] = grad[j] - y[i] * X[i][j]\n",
    "\n",
    "                \n",
    "def update():\n",
    "    for j in range(0,features):\n",
    "        w[j] = w[j] - lr*grad[j]\n",
    "        \n",
    "def train(m,X,y):\n",
    "\n",
    "    for it in range (0,iter):\n",
    "        costAndGrad(m,X,y)\n",
    "        #print(\"cost:\",cost);\n",
    "        if(cost<accuracy):\n",
    "            print(\"cost < accuracy\")\n",
    "            break\n",
    "        update()\n",
    "\n",
    "def predict(x):\n",
    "    pre = 0.0\n",
    "    for j in range (0,features):\n",
    "        pre = pre + x[j] * w[j]\n",
    "        \n",
    "    if(pre>=0) :\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "train(m,X,y)\n",
    "print(w)\n",
    "    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
